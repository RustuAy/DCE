# DA-5 ile Titanic: Staj MÃ¼lakatleri Ä°Ã§in UygulamalÄ± EÄŸitim Rehberi ğŸ’¼ğŸ“Š

_**Not:** Bu dokÃ¼man aday perspektifiyle yazÄ±lmÄ±ÅŸtÄ±r â€” cevaplar "Ben â€¦" ÅŸeklinde Ã¶rnek ifadeler iÃ§erir. AmaÃ§: hem pratik bir Ã§alÄ±ÅŸma rehberi hem de staj mÃ¼lakatlarÄ±nda sÄ±kÃ§a sorulan sorulara hazÄ±r; uygulanabilir cevaplar ve kÃ¼Ã§Ã¼k uygulama adÄ±mlarÄ± iÃ§ermek._

---

## Ã–zet (Ne elde edeceÄŸim)
Ben bu rehberle Titanic veri setini kullanarak DA-5 (Define, Acquire, Assess, Analyze, Act) Ã§erÃ§evesine gÃ¶re adÄ±m adÄ±m ilerleyeceÄŸim. Her adÄ±mda:
- Ne yapacaÄŸÄ±mÄ± kÄ±sa aÃ§Ä±klama ÅŸeklinde okurum âœ…
- Uygulama (kod) adÄ±mÄ± yaparÄ±m âœ…
- MÃ¼lakatta gelebilecek soru Ã¶rnekleri ve kendi cÃ¼mlelerimle kÄ±sa cevaplar hazÄ±rlarÄ±m âœ…
- KÄ±sa Ã¶dev veya alÄ±ÅŸtÄ±rma verilir, baÅŸarÄ± Ã¶lÃ§Ã¼tÃ¼ belirtilir âœ…

---

## DA-5 adÄ±mlarÄ± kÄ±sa (baÅŸlÄ±klar)
1. Define â€” Problemi tanÄ±mlama
2. Acquire â€” Veri edinme ve doÄŸrulama
3. Assess â€” Veri kalitesi ve hazÄ±rlÄ±k
4. Analyze â€” KeÅŸifsel Veri Analizi ve Basit Modeller
5. Act â€” SonuÃ§larÄ± sunma ve aksiyon Ã¶nerileri

---

## 1) DEFINE â€” Problemi tanÄ±mlama ğŸ¯
Ne yaparÄ±m (Ã¶zet):
- Hedefi net olarak cÃ¼mleleÅŸtiririm: "Bu projede hedefim `Survived` sÃ¼tununu kullanarak yolcularÄ±n kurtulma olasÄ±lÄ±ÄŸÄ±nÄ± anlamak/Ã¶ngÃ¶rmek." 
- AmaÃ§larÄ± (baÅŸarÄ± Ã¶lÃ§Ã¼tlerini) belirlerim: doÄŸruluk, basit yorumlanabilirlik, ya da etkileyici bir gÃ¶rselleÅŸtirme gibi.

KÄ±sa Uygulama - Not: Bu hÃ¼cre sadece dÃ¼ÅŸÃ¼nme adÄ±mÄ±dÄ±r (kod yok):
- YazÄ±lacak not:
  - Hedef: "KÄ±sa ve anlaÅŸÄ±lÄ±r model ile yolcunun hayatta kalÄ±p kalmayacaÄŸÄ±nÄ± %X doÄŸrulukla tahmin etmek." 
  - KPI: **Accuracy** (doÄŸruluk â€” modelin tÃ¼m tahminler iÃ§inde doÄŸru yaptÄ±ÄŸÄ± tahminlerin oranÄ±) > %75 (Ã¶rnek), fakat aÃ§Ä±kla ki bu hedef dataset'e gÃ¶re deÄŸiÅŸebilir.

MÃ¼lakat sorularÄ± ve Ã¶rnek cevaplar:
- Soru: "Problem tanÄ±mÄ±nÄ± nasÄ±l yaparsÄ±nÄ±z?" 
  - Cevap (Ã¶rnek): "Ã–nce hedef deÄŸiÅŸkeni ve baÅŸarÄ±nÄ±n nasÄ±l Ã¶lÃ§Ã¼leceÄŸini netleÅŸtiririm. Bu projede hedefimiz `Survived`. BaÅŸarÄ±yÄ± **accuracy** (doÄŸruluk â€” doÄŸru tahmin oranÄ±), **F1** (F1 skoru â€” precision ve recall'un harmonik ortalamasÄ±; dengesiz sÄ±nÄ±flarda anlamlÄ±dÄ±r) veya **AUC** (ROC eÄŸrisi altÄ±ndaki alan â€” modelin sÄ±nÄ±flarÄ± ayÄ±rt etme yeteneÄŸini gÃ¶sterir) ile Ã¶lÃ§erim ve baÅŸta basit hedefler belirlerim (Ã¶rn. accuracy > %70)."
- Soru: "Bu projede hangi paydaÅŸlar olacak, hangi iÅŸ kararlarÄ± etkilenebilir?"
  - Cevap: "PaydaÅŸ Ã¶rneÄŸin eÄŸitim amaÃ§lÄ± veya yarÄ±ÅŸma amaÃ§lÄ± olabilir; mÃ¼ÅŸteri iÃ§inse sonuÃ§lar tahsis edilen kaynaklara (koltuk rezervasyonu, kurtarma planlarÄ± gibi) Ä±ÅŸÄ±k tutabilir."

AlÄ±ÅŸtÄ±rma:
- Kendin iÃ§in hedef ve KPI yaz: 1-2 cÃ¼mleyle.
- DeÄŸerlendirme: Hedef ve KPI net ve Ã¶lÃ§Ã¼lebilir mi?

---

## 2) ACQUIRE â€” Veri edinme & doÄŸrulama ğŸ“‚
Ne yaparÄ±m (Ã¶zet):
- CSV dosyasÄ±nÄ± gÃ¼venli ve tekrar edilebilir ÅŸekilde notebook'a yÃ¼klerim.
- DosyanÄ±n mevcut lokasyonunu doÄŸrular, kopyalama tercihini kararlaÅŸtÄ±rÄ±rÄ±m (proje iÃ§erisindeki `data/` Ã¶nerilir).

KÄ±sa Kod (Notebook hÃ¼cresi - Ã§alÄ±ÅŸtÄ±rÄ±labilir):
```python
# 1) KÃ¼tÃ¼phaneler
from pathlib import Path
import pandas as pd

# 2) Dosya yolu (Ã¶rnek)
data_path = Path(r"C:\Users\User\Desktop\Dataset\titanic.csv")

# 3) Var mÄ± kontrol et
if not data_path.exists():
    raise FileNotFoundError(f"Dosya yok: {data_path}")

# 4) Oku
df = pd.read_csv(data_path)
print('Okundu:', df.shape)
```

MÃ¼lakat sorularÄ± ve Ã¶rnek cevaplar:
- Soru: "Veriyi nasÄ±l alÄ±rsÄ±nÄ±z ve doÄŸrularsÄ±nÄ±z?"
  - Cevap: "Dosya yolunu kontrol ederim, dosyayÄ± `pandas.read_csv` ile okurum, satÄ±r/sÃ¼tun sayÄ±sÄ±nÄ± ve ilk 5 satÄ±rÄ± doÄŸrularÄ±m. Kopyala-yapÄ±ÅŸtÄ±r yerine proje iÃ§i `data/` kullanmayÄ± tercih ederim; bÃ¶ylece Ã§alÄ±ÅŸma tekrar edilebilir olur." 

AlÄ±ÅŸtÄ±rma:
- YukarÄ±daki kodu Ã§alÄ±ÅŸtÄ±r ve `df.shape`, `df.head()` Ã§Ä±ktÄ±sÄ±nÄ± kopyala.
- DeÄŸerlendirme: DosyayÄ± bulup okuyabiliyor musun?

---

## 3) ASSESS â€” Veri kalitesi & hazÄ±rlÄ±k ğŸ§¹
Ne yaparÄ±m (Ã¶zet):
- `df.info()`, `df.isnull().sum()` ile veri eksikliklerini gÃ¶rÃ¼rÃ¼m.
- Eksik deÄŸer stratejileri seÃ§erim (drop? impute? Ã¶zel deÄŸer?).
- Kategorik deÄŸiÅŸkenleri inceleyip dÃ¶nÃ¼ÅŸÃ¼m planÄ± yaparÄ±m.

KÄ±sa Kod (Notebook hÃ¼cresi - Ã§alÄ±ÅŸtÄ±rÄ±labilir):
```python
# Temel kontroller
print(df.info())
print('\nEksikler:\n', df.isnull().sum())

# Ã–rnek small fix: Age iÃ§in median ile doldurma (Ã¶rnek adÄ±m)
df['Age_filled'] = df['Age'].fillna(df['Age'].median())

# KÄ±sa kontrol
print('Age eksik kalÄ±r mÄ±?', df['Age_filled'].isnull().any())
```

MÃ¼lakat sorularÄ± ve Ã¶rnek cevaplar:
- Soru: "Eksik verilerle nasÄ±l uÄŸraÅŸÄ±rsÄ±nÄ±z?" 
  - Cevap: "Eksik verinin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶zlemler, mekanizmasÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±rÄ±m (MCAR/MAR/MNAR). HÄ±zlÄ± bir prototip iÃ§in numeric'leri median/mean ile doldururum, kategoriklerde 'Unknown' veya en sÄ±k kategoriyle doldurma uygundur. BÃ¼yÃ¼k oranda eksik bir sÃ¼tun varsa (Ã¶rn. Cabin) o sÃ¼tunu dÃ¼ÅŸÃ¼nebilirim veya farklÄ± bir feature engineering yaparÄ±m." 
- Soru: "Neden median yerine mean kullanmayÄ±z?"
  - Cevap: "Ortalama uÃ§ deÄŸerlere daha hassastÄ±r; median daha dayanÄ±klÄ±dÄ±r, Ã¶zellikle age gibi skewed daÄŸÄ±lÄ±mlarda." 

AlÄ±ÅŸtÄ±rma:
- `Age` iÃ§in median ve mean deÄŸerlerini hesapla; arada fark varsa not et. `Age` eksiklerini median ile doldur.
- DeÄŸerlendirme: Eksiklikler azaldÄ± mÄ±? (Ã¶rn. `df.isnull().sum()` tekrar Ã§alÄ±ÅŸtÄ±r)

---

## 4) ANALYZE â€” KeÅŸifsel analiz & basit modelleme ğŸ“ˆ
Ne yaparÄ±m (Ã¶zet):
- SÄ±nÄ±flayÄ±cÄ± olarak basit bir model (Ã¶rn. Logistic Regression) kurarÄ±m; pipeline ile eksik doldurma + encoding + model.
- AyrÄ±ca pivot/tablo ve basit gÃ¶rselleÅŸtirmeler yaparÄ±m (Ã¶r: hayatta kalma oranÄ± sÄ±nÄ±fa gÃ¶re).

KÄ±sa Kod (Notebook hÃ¼cresi - Ã§alÄ±ÅŸtÄ±rÄ±labilir) â€” EDA:
```python
# Basit pivot
print(df.groupby('Pclass')['Survived'].mean())

# Cinsiyete gÃ¶re hayatta kalma
print(df.groupby('Sex')['Survived'].mean())
```

KÄ±sa Kod â€” Basit model (sklearn ile):
```python
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Base features
features = ['Pclass', 'Sex', 'Age_filled', 'Fare']
X = df[features]
y = df['Survived']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# Transformer
numeric_feats = ['Age_filled','Fare']
cat_feats = ['Pclass','Sex']
pre = ColumnTransformer([
    ('num', SimpleImputer(strategy='median'), numeric_feats),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_feats)
])

pipe = make_pipeline(pre, LogisticRegression(max_iter=1000))
pipe.fit(X_train, y_train)
print('Test accuracy:', accuracy_score(y_test, pipe.predict(X_test)))
```

MÃ¼lakat sorularÄ± ve Ã¶rnek cevaplar:
- Soru: "Model performansÄ±nÄ± nasÄ±l deÄŸerlendirirsiniz?"
  - Cevap: "Ä°lk olarak **accuracy** (doÄŸruluk), **precision** (kesinlik â€” pozitif tahminlerin kaÃ§Ä±nÄ±n doÄŸru olduÄŸunu gÃ¶sterir), **recall** (duyarlÄ±lÄ±k â€” gerÃ§ek pozitiflerin kaÃ§Ä±nÄ±n yakalandÄ±ÄŸÄ±nÄ± gÃ¶sterir) ve **AUC** (ROC eÄŸrisi altÄ±ndaki alan) deÄŸerlerini kontrol ederim; dengesiz sÄ±nÄ±f varsa accuracy yanÄ±ltÄ±cÄ± olabilir. AyrÄ±ca basit bir baseline (Ã¶rn. random veya most-frequent) ile karÅŸÄ±laÅŸtÄ±rÄ±rÄ±m." 
- Soru: "Feature seÃ§imi nasÄ±l yaparsÄ±nÄ±z?"
  - Cevap: "Ã–ncelikle domain bilgisi, ardÄ±ndan korelasyon ve model bazlÄ± Ã¶nem sÄ±ralamasÄ± ile seÃ§erim; fazla feature varsa regularizasyon veya seÃ§me yÃ¶ntemleri kullanÄ±rÄ±m." 

AlÄ±ÅŸtÄ±rma:
- YukarÄ±daki pipeline'Ä± Ã§alÄ±ÅŸtÄ±r. Test doÄŸruluÄŸunu raporla.
- DeÄŸerlendirme: Model baseline'in Ã¼zerinde mi?

---

## 5) ACT â€” SonuÃ§larÄ± sunma & aksiyon Ã¶nerileri ğŸ“£
Ne yaparÄ±m (Ã¶zet):
- SonuÃ§larÄ± aÃ§Ä±k, kÄ±sa ve gÃ¶rselleÅŸtirilmiÅŸ bir rapor halinde sunarÄ±m (Ã¶r: Jupyter -> PDF/HTML veya PowerPoint'te birkaÃ§ slide).
- Ã–neriler ve limitasyonlar bÃ¶lÃ¼mÃ¼nÃ¼ eklerim (Ã¶r: veri bias, eksik veriler, model belirsizliÄŸi).

Sunum kontrol listesi (Ã¶rnek):
- 2-3 slayt: Problem, veri + temel bulgular, Ã¶neriler
- Bir cÃ¼mlede sonuÃ§: "Pclass ve Sex en belirleyici iki Ã¶zellik" gibi
- Limitasyonlar: "Cabin sÃ¼tunu Ã§ok eksik, bu feature gÃ¼venilir deÄŸil"

MÃ¼lakat sorularÄ± ve Ã¶rnek cevaplar:
- Soru: "SonuÃ§larÄ± nasÄ±l sunarsÄ±nÄ±z?"
  - Cevap: "KÄ±sa, gÃ¶rsel ve aksiyon odaklÄ± sunarÄ±m: 1) problem tanÄ±mÄ±, 2) Ã¶nemli bulgular, 3) Ã¶neriler (ve riskler).

AlÄ±ÅŸtÄ±rma:
- Basit bir gÃ¶rselleÅŸtirme oluÅŸtur (Ã¶rn. Pclass vs Survived bar chart). Sunum slaytlarÄ± iÃ§in 3 kÄ±sa madde yaz.

---

## Ek BÃ¶lÃ¼m: MÃ¼lakatta Teknik ve DavranÄ±ÅŸsal Sorulara KÄ±sa Notlar
- Teknik Ã¶rnekler: "Veri eksikliÄŸi ile nasÄ±l baÅŸa Ã§Ä±karsÄ±n?", "Model overfitting'i nasÄ±l anlarsÄ±n?" â€” cevaplarda Ã¶nce ANALÄ°Z akÄ±ÅŸÄ±nÄ± (DA-5) belirtirim, sonra kÄ±sa teknik Ã§Ã¶zÃ¼mÃ¼ sÃ¶ylerim.
- DavranÄ±ÅŸsal: "TakÄ±m iÃ§inde zor karar aldÄ±ÄŸÄ±n bir Ã¶rnek?" â€” STAR (Situation, Task, Action, Result) formatÄ±nÄ± kullanÄ±rÄ±m.

---

## HÄ±zlÄ± Cheat-sheet (Kopyala-yapÄ±ÅŸtÄ±r iÃ§in kÃ¼Ã§Ã¼k kod parÃ§alarÄ±)
- Dosya okuma:
```python
from pathlib import Path
import pandas as pd
df = pd.read_csv(Path(r"C:\Users\User\Desktop\Dataset\titanic.csv"))
```
- Eksik kontrol:
```python
print(df.info())
print(df.isnull().sum())
```
- Median ile doldurma:
```python
df['Age'] = df['Age'].fillna(df['Age'].median())
```

---

## Son SÃ¶z
"Bu rehberi takip ederek hem pratik bir proje yapmÄ±ÅŸ olacaÄŸÄ±m, hem de staj mÃ¼lakatlarÄ±nda sÄ±kÃ§a sorulan sorularÄ± cevaplarken DA-5 yapÄ± taÅŸÄ± gibi kullanabileceÄŸim kÄ±sa, mantÄ±klÄ± argÃ¼manlara sahip olacaÄŸÄ±m.

---
